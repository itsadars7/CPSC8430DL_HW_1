{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3631ed34-d858-4a11-9d91-3758b6d1ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b21fd16-4619-4494-94da-e3c70198a061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUT_DIR = \"HW_1-2-GradientNorm\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74aa7da5-7b0a-466f-8ff2-95127e6e24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9d2359-d5cf-446e-91c1-66b5ae2225f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device():\n",
    "    if torch.cuda.is_available(): return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55c9a0b-7964-4c57-a9eb-3bf07c4b667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_norm(model: nn.Module) -> float:\n",
    "    grad_all = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            grad_all += (p.grad.detach() ** 2).sum().item()\n",
    "    grad_norm = grad_all ** 0.5\n",
    "    return grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55554b00-9a6b-4317-92c3-1ea721a72558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_and_loss(grad_hist, loss_hist, title, out_path):\n",
    "    iters = np.arange(1, len(loss_hist) + 1)\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8.5, 6.5), sharex=True)\n",
    "    ax1.plot(iters, grad_hist, linewidth=1)\n",
    "    ax1.set_ylabel(\"grad\"); ax1.grid(True, linewidth=0.3)\n",
    "    ax2.plot(iters, loss_hist, linewidth=1)\n",
    "    ax2.set_xlabel(\"iteration\"); ax2.set_ylabel(\"loss\"); ax2.grid(True, linewidth=0.3)\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout(rect=[0,0,1,0.96])\n",
    "    plt.savefig(out_path, dpi=180); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "524f3973-865f-4fce-896c-c29b6a401d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Single-input Single-output function\n",
    "def f_true(x: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.cos(2* math.pi*x) * (x**3)\n",
    "\n",
    "def make_function_loaders(xmin=-3.0, xmax=3.0, n_train=256, batch=64, device=None):\n",
    "    x = torch.linspace(xmin, xmax, n_train).unsqueeze(1)\n",
    "    y = f_true(x)\n",
    "    ds = TensorDataset(x, y)\n",
    "    loader = DataLoader(ds, batch_size=batch, shuffle=True, drop_last=False)\n",
    "    if device:\n",
    "        pass\n",
    "    return loader\n",
    "\n",
    "class SimpleFunctionModel(nn.Module):\n",
    "    def __init__(self, hidden=[18, 20, 15]):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_d = 1\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(in_d, h), nn.Tanh()]\n",
    "            in_d = h\n",
    "        layers += [nn.Linear(in_d, 1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x): return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a73aa7f-8561-41c3-96e4-3bd73f0cee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_function_gradnorm(epochs=1000, lr=1e-3, wd=5e-4, batch=128):\n",
    "    dev = device()\n",
    "    loader = make_function_loaders(batch=batch)\n",
    "    model = SimpleFunctionModel([18, 20, 15]).to(dev)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    grad_hist, loss_hist = [], []\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in loader:\n",
    "            xb,yb = xb.to(dev), yb.to(dev)\n",
    "            opt.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred,yb)\n",
    "            loss.backward()\n",
    "            grad_hist.append(grad_norm(model))\n",
    "            loss_hist.append(loss.item())\n",
    "            opt.step()\n",
    "    plot_grad_and_loss(grad_hist, loss_hist,\n",
    "                       f\"Grad-norm & Loss vs Iterations [Function]\",\n",
    "                       f\"{OUT_DIR}/gradloss_function.png\")\n",
    "    print(\"Saved function plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6105bd14-0919-402b-ae53-d65887c63054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_channel_stats(data_dir=\"./data\"):\n",
    "    \"\"\"\n",
    "    Compute mean and std of CIFAR-10 training set.\n",
    "    Returns two lists: mean, std (each of length 3 for RGB).\n",
    "    \"\"\"\n",
    "    # Load train set\n",
    "    train_set = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True,\n",
    "        transform=T.ToTensor()\n",
    "    )\n",
    "    loader = DataLoader(train_set, batch_size=5000, shuffle=False, num_workers=2)\n",
    "\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0\n",
    "\n",
    "    for data, _ in loader:\n",
    "        # data shape: [batch, channels, height, width]\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)  # flatten H*W\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std  += data.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "\n",
    "    return mean.tolist(), std.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "911ba1eb-75b8-4013-b6bf-e115282a13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_loaders(\n",
    "    data_dir=\"./data\",\n",
    "    batch_size=128,\n",
    "    num_workers=2,\n",
    "    drop_last=False\n",
    "):\n",
    "    # compute mean/std\n",
    "    mean, std = compute_channel_stats(data_dir)\n",
    "    print(\"CIFAR-10 stats:\", mean, std)\n",
    "\n",
    "    train_tfms = T.Compose([\n",
    "        T.RandomCrop(32, padding=2),\n",
    "        T.RandomHorizontalFlip(), \n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std),\n",
    "    ])\n",
    "    test_tfms = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=train_tfms\n",
    "    )\n",
    "    test_set = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=test_tfms\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True, drop_last=drop_last\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True, drop_last=False\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e2dac4-6502-40aa-a4bf-10a5eb60f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(inplace=True),   # <-- 'features.0' is first conv\n",
    "            nn.MaxPool2d(2),  # 32x16x16\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 64x8x8\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*8*8, 128), nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "    def forward(self, x): return self.classifier(self.features(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da0c03c-fb9e-48f6-bbde-e16035f580ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cifar_gradnorm(epochs=5, lr=1e-3, wd=5e-4, batch=128, data_dir=\"./data\"):\n",
    "    train_loader, _ = get_cifar10_loaders(data_dir=data_dir, batch_size=batch)\n",
    "\n",
    "    dev = device()\n",
    "    model = CNNModel().to(dev)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    grad_hist, loss_hist = [], []\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in train_loader:\n",
    "            xb,yb = xb.to(dev), yb.to(dev)\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = loss_fn(logits,yb)\n",
    "            loss.backward()\n",
    "            grad_hist.append(grad_norm(model))\n",
    "            loss_hist.append(loss.item())\n",
    "            opt.step()\n",
    "    plot_grad_and_loss(grad_hist, loss_hist,\n",
    "                       f\"Grad-norm & Loss vs Iterations [CIFAR-10]\",\n",
    "                       f\"{OUT_DIR}/gradloss_cifar.png\")\n",
    "    print(\"Saved CIFAR plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c60d998-5bd6-4372-8b16-004d14e40f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(task=\"both\",\n",
    "         epochs=20,\n",
    "         lr=1e-3,\n",
    "         weight_decay=5e-4,\n",
    "         batch=128,\n",
    "         data_dir=\"./data\"):\n",
    "\n",
    "    set_seed(42)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "\n",
    "    if task in (\"function\", \"both\"):\n",
    "        run_function_gradnorm(epochs=epochs, lr=lr, wd=weight_decay,\n",
    "                              batch=batch)\n",
    "\n",
    "    if task in (\"cifar\", \"both\"):\n",
    "        run_cifar_gradnorm(epochs=epochs, lr=lr, wd=weight_decay,\n",
    "                           batch=batch, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0740a515-8b2c-4824-acf1-60698a3a1be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Saved function plot.\n",
      "Device: cuda\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adarshn/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 stats: [0.4913996756076813, 0.4821583926677704, 0.44653093814849854] [0.20230092108249664, 0.19941280782222748, 0.20096160471439362]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Saved CIFAR plot.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(task=\"function\", epochs=5000)\n",
    "    main(task=\"cifar\", epochs=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

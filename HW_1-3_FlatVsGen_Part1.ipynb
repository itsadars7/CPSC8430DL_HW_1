{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee75d1-7c87-4d89-9eef-06a4d38a1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os, random, numpy as np, torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129167f-bf76-4dbd-8be0-99b96e8bda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9157b-b032-419a-bf27-a23f3f71550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available(): return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb07df-bfed-4eb2-9f8a-21024a88b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 data\n",
    "def get_cifar10_loaders(batch_train=128, batch_test=256, data_dir=\"./data\"):\n",
    "    mean=(0.4914,0.4822,0.4465); std=(0.2023,0.1994,0.2010) # values obtained from running previous code for HW_1_2\n",
    "    tf = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
    "    train = torchvision.datasets.CIFAR10(root=data_dir, train=True,  download=True, transform=tf)\n",
    "    test  = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=tf)\n",
    "    train_loader = DataLoader(train, batch_size=batch_train, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test,  batch_size=batch_test,  shuffle=False, num_workers=2, pin_memory=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad3cc3-a693-42c3-8781-c8fe1a05a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64,64,3,padding=1),   nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 64x16x16\n",
    "            nn.Conv2d(64,128,3,padding=1),  nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128,128,3,padding=1), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 128x8x8\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*8*8, 256), nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "    def forward(self,x): return self.classifier(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77091dc3-e5d2-49af-b7c4-8ba2a465eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training and testing\n",
    "def train_epochs(model, train_loader, epochs=10, lr=1e-3, weight_decay=0.0, device=None):\n",
    "    device = device or get_device()\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device=None):\n",
    "    device = device or get_device()\n",
    "    model.eval().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    tot_loss, tot, correct = 0.0, 0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        tot_loss += loss.item() * xb.size(0)\n",
    "        correct  += (logits.argmax(1) == yb).sum().item()\n",
    "        tot += xb.size(0)\n",
    "    return tot_loss / tot, correct / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c4490-e501-493a-91fd-d0b98987b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_models(model1: nn.Module, model2: nn.Module, alpha: float) -> nn.Module:\n",
    "    \"\"\"Return a new model whose parameters are (1-alpha)*theta1 + alpha*theta2.\"\"\"\n",
    "    m_new = CNN()  # same architecture\n",
    "    sd1 = model1.state_dict()\n",
    "    sd2 = model2.state_dict()\n",
    "    sd_new = {}\n",
    "    for k in sd1.keys():\n",
    "        sd_new[k] = (1.0 - alpha) * sd1[k] + alpha * sd2[k]\n",
    "    m_new.load_state_dict(sd_new, strict=True)\n",
    "    return m_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22de905-4aa8-4b8d-8d38-17cdfc345003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_eval(model1, model2, alphas, train_loader, test_loader, device=None):\n",
    "    \"\"\"Evaluate train/test loss & accuracy for interpolated models across alphas.\"\"\"\n",
    "    device = device or get_device()\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accs,   test_accs   = [], []\n",
    "    for a in alphas:\n",
    "        m = interpolate_models(model1, model2, a).to(device)\n",
    "        tr_loss, tr_acc = evaluate(m, train_loader, device)\n",
    "        te_loss, te_acc = evaluate(m, test_loader,  device)\n",
    "        train_losses.append(tr_loss); train_accs.append(tr_acc)\n",
    "        test_losses.append(te_loss);  test_accs.append(te_acc)\n",
    "    return train_losses, test_losses, train_accs, test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c5d15-2c9a-4e92-982b-c3ecab45c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "def plot_loss_and_acc(alphas, tr_loss, te_loss, tr_acc, te_acc, title, out=None):\n",
    "    fig, ax1 = plt.subplots(figsize=(8.5,5.2))\n",
    "    ax1.plot(alphas, tr_loss, label=\"train loss\", linewidth=1.5, color=\"tab:blue\")\n",
    "    ax1.plot(alphas, te_loss, label=\"test loss\",  linewidth=1.5, color=\"tab:blue\", linestyle=\"--\")\n",
    "    ax1.set_xlabel(\"alpha\"); ax1.set_ylabel(\"cross-entropy\", color=\"tab:blue\")\n",
    "    ax1.grid(True, linewidth=0.3)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(alphas, tr_acc, label=\"train acc\", linewidth=1.5, color=\"tab:red\")\n",
    "    ax2.plot(alphas, te_acc, label=\"test acc\",  linewidth=1.5, color=\"tab:red\", linestyle=\"--\")\n",
    "    ax2.set_ylabel(\"accuracy\", color=\"tab:red\")\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines+lines2, labels+labels2, loc=\"best\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if out:\n",
    "        os.makedirs(os.path.dirname(out), exist_ok=True)\n",
    "        plt.savefig(out, dpi=180)\n",
    "    plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2adf8ad-447f-4c12-bf6f-1e845e9a1d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    epochs1=20, epochs2=20,\n",
    "    batch_train_1=64, batch_train_2=1024,   # different training approaches (batch sizes)\n",
    "    lr1=1e-3, lr2=1e-4, # different learning rates for both models\n",
    "    data_dir=\"./data\",\n",
    "    alphas=None,\n",
    "    out_dir=\"HW_1-3_FlatVsGen_Part1\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train two CNNs with different training settings, then evaluate the line interpolations.\n",
    "    \"\"\"\n",
    "    set_seed(42)\n",
    "    dev = get_device()\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    if alphas is None:\n",
    "        alphas = np.linspace(-1.0, 2.0, 61) \n",
    "\n",
    "    # Loaders for evaluation (use a consistent batch size)\n",
    "    train_loader_1, test_loader   = get_cifar10_loaders(batch_train=batch_train_1, data_dir=data_dir)\n",
    "    train_loader_2, _             = get_cifar10_loaders(batch_train=batch_train_2, data_dir=data_dir)\n",
    "\n",
    "    # Train model m1\n",
    "    m1 = CNN()\n",
    "    m1 = train_epochs(m1, train_loader_1, epochs=epochs1, lr=lr1, device=dev)\n",
    "\n",
    "    # Train model m2 \n",
    "    m2 = CNN()\n",
    "    m2 = train_epochs(m2, train_loader_2, epochs=epochs2, lr=lr2, device=dev)\n",
    "\n",
    "    # Evaluate interpolations\n",
    "    tr_loss, te_loss, tr_acc, te_acc = line_eval(m1, m2, alphas, train_loader_1, test_loader, device=dev)\n",
    "\n",
    "    # Plot\n",
    "    out_path = os.path.join(out_dir, \"cifar_interpolation_loss_acc.png\")\n",
    "    plot_loss_and_acc(alphas, tr_loss, te_loss, tr_acc, te_acc,\n",
    "                      title=f\"CIFAR-10: model 1 vs model 2 (bs={batch_train_1} vs {batch_train_2})\",\n",
    "                      out=out_path)\n",
    "    print(\"Saved:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd3e34-d6f5-4bb9-b4f4-1c1bddaa4ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

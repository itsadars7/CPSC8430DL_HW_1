{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f733da-003f-4cbc-872b-82eb0ce1f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os, random, numpy as np, torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee465636-7f11-4e47-88c5-ada441926554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ddaba-19ee-4d43-b85b-f30fe9294b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available(): return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace8f5e-fe25-41bd-8700-c97381a55d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce6b16-2cdf-42f6-a1e2-1a798565ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 data\n",
    "def get_cifar10_loaders(data_dir=\"./data\", batch=128, workers=2):\n",
    "    # Standard CIFAR-10 stats (or compute if you prefer)\n",
    "    mean=(0.4914,0.4822,0.4465); std=(0.2023,0.1994,0.2010)\n",
    "    tf = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
    "    train_set = torchvision.datasets.CIFAR10(root=data_dir, train=True,  download=True, transform=tf)\n",
    "    test_set  = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=tf)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch, shuffle=True,  num_workers=workers, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_set,  batch_size=batch, shuffle=False, num_workers=workers, pin_memory=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211befc8-5141-41a6-8367-c093077ea879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model family of CNN\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Base stages: [16, 32, 64] channels; scaled by 'w' (float multiplier).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10, width_mult: float = 1.0):\n",
    "        super().__init__()\n",
    "        c1 = max(8, int(16 * width_mult))\n",
    "        c2 = max(8, int(32 * width_mult))\n",
    "        c3 = max(16, int(64 * width_mult))\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, c1, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(c1, c1, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                        # c1 x 16 x 16\n",
    "            nn.Conv2d(c1, c2, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(c2, c2, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                        # c2 x 8 x 8\n",
    "            nn.Conv2d(c2, c3, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(c3, c3, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),           # c3 x 1 x 1\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(c3, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.classifier(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcfd64-6532-4d3a-aa24-332b28988319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test\n",
    "def train_one_epoch(model, loader, opt, loss_fn, device):\n",
    "    model.train()\n",
    "    tot_loss, tot, correct = 0.0, 0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tot_loss += loss.item() * xb.size(0)\n",
    "        correct += (logits.argmax(1) == yb).sum().item()\n",
    "        tot += xb.size(0)\n",
    "    return tot_loss/tot, correct/tot\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    tot_loss, tot, correct = 0.0, 0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        tot_loss += loss.item() * xb.size(0)\n",
    "        correct += (logits.argmax(1) == yb).sum().item()\n",
    "        tot += xb.size(0)\n",
    "    return tot_loss/tot, correct/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b3ce3-619e-479c-ae21-374c6113e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(width_list=None, epochs=10, lr=1e-3, weight_decay=0.0,\n",
    "                          batch=128, data_dir=\"./data\", out_dir=\"HW_1-3_ParamVsGen\"):\n",
    "    \"\"\"\n",
    "    Trains the same CNN with different width multipliers; logs train/test loss & acc,\n",
    "    and plots them vs number of parameters.\n",
    "    \"\"\"\n",
    "    if width_list is None:\n",
    "        # 10 models\n",
    "        width_list = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0]\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    set_seed(42)\n",
    "    dev = get_device()\n",
    "    train_loader, test_loader = get_cifar10_loaders(data_dir=data_dir, batch=batch)\n",
    "\n",
    "    # storage\n",
    "    param_counts = []\n",
    "    train_losses = []; test_losses = []\n",
    "    train_accs   = []; test_accs   = []\n",
    "\n",
    "    for w in width_list:\n",
    "        model = CNN(width_mult=w).to(dev)\n",
    "        params = count_parameters(model)\n",
    "        param_counts.append(params)\n",
    "\n",
    "        opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # train\n",
    "        for ep in range(1, epochs+1):\n",
    "            tr_loss, tr_acc = train_one_epoch(model, train_loader, opt, loss_fn, dev)\n",
    "        # evaluate after final epoch\n",
    "        te_loss, te_acc = evaluate(model, test_loader, loss_fn, dev)\n",
    "\n",
    "        train_losses.append(tr_loss); test_losses.append(te_loss)\n",
    "        train_accs.append(tr_acc);   test_accs.append(te_acc)\n",
    "\n",
    "        print(f\"w={w:>4} | params={params:>8,d} | \"\n",
    "              f\"train loss {tr_loss:.3f} acc {tr_acc*100:5.1f}% | \"\n",
    "              f\"test loss {te_loss:.3f} acc {te_acc*100:5.1f}%\")\n",
    "\n",
    "    # Loss vs #params plot\n",
    "    plt.figure(figsize=(9,4.8))\n",
    "    plt.scatter(param_counts, train_losses, label=\"train_loss\")\n",
    "    plt.scatter(param_counts, test_losses,  label=\"test_loss\")\n",
    "    plt.xlabel(\"number of parameters\"); plt.ylabel(\"loss\"); plt.title(\"model loss\")\n",
    "    plt.grid(True, linewidth=0.3); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(out_dir, \"loss_vs_params.png\"), dpi=180); plt.show(); plt.close()\n",
    "\n",
    "    # Accuracy vs #params loss\n",
    "    plt.figure(figsize=(9,4.8))\n",
    "    plt.scatter(param_counts, train_accs, label=\"train_acc\")\n",
    "    plt.scatter(param_counts, test_accs,  label=\"test_acc\")\n",
    "    plt.xlabel(\"number of parameters\"); plt.ylabel(\"accuracy\"); plt.title(\"model accuracy\")\n",
    "    plt.grid(True, linewidth=0.3); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(out_dir, \"acc_vs_params.png\"), dpi=180); plt.show(); plt.close()\n",
    "\n",
    "    return {\n",
    "        \"params\": param_counts,\n",
    "        \"train_loss\": train_losses, \"test_loss\": test_losses,\n",
    "        \"train_acc\": train_accs,   \"test_acc\": test_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140dc395-3436-48ac-8c96-f7236de80064",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
